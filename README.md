# Web-Scrapping

- Étape 1 : Lancer tout d'abord le fichier cleanFonc.py pour récupérer les données des 6 premières pages
(ce nombre est modifiable dans la fonction responseLon, à la ligne 259).
On peut récupérer les données de location pour cela il faut mettre l'url présente dans le token 2 à la ligne 28.
Les données récupérées seront enregistrées dans un nouveau fichier csv : recup.csv, générer automatiquement sinon créer et écraser à chaque nouvel appel.

- Étape 2 :  Lancer maintenant le fichier analyse.py pour récupérer un nouveau fichier csv sans les données aberrantes,nulles,(doublon).
On récupere les données propres dans un fichier recup_clean.csv

- Étape 3 : On lance en dernier le fichier dataClean.py	pour afficher les graphiques


Le fichier testUnit.py contient peu de test.

Undersupervision of M.Ouziri
